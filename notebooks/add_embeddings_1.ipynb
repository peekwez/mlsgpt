{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession, DataFrame, Row\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.errors import AnalysisException\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env-deploy\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = \"/Users/kwesi/Desktop/ai/gpts/mlsgpt/data\"\n",
    "jar_files = [\"postgresql-42.7.3.jar\", \"mysql-connector-j-8.0.33.jar\"]\n",
    "jar_opts = \",\".join([f\"{data_home}/jars/{jar}\" for jar in jar_files])\n",
    "warehouse = f\"{data_home}/warehouse\"\n",
    "\n",
    "spark: SparkSession = (\n",
    "    SparkSession.builder\\\n",
    "    .appName(\"MLSGPT\")\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .config(\"spark.shuffle.service.enabled\", \"true\")\n",
    "    .config(\"spark.sql.warehouse.dir\", f\"{warehouse}\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "    .config(\"spark.jars\", f\"{jar_opts}\") \n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table(url:str, props:dict, table_name: str, ) -> DataFrame:\n",
    "    try:\n",
    "        return spark.read.jdbc(url=url, table=table_name, properties=props)\n",
    "    except AnalysisException as e:\n",
    "        print(f\"Table {table_name} not found\")\n",
    "        return None\n",
    "    \n",
    "pg_url = \"jdbc:postgresql://{}:{}/{}\".format(os.getenv(\"POSTGRES_HOST\"), os.getenv(\"POSTGRES_PORT\"),os.getenv(\"POSTGRES_DB\"))\n",
    "pg_props = {\n",
    "    \"user\": os.getenv(\"POSTGRES_USER\"),\n",
    "    \"password\": os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = (\n",
    "    read_table(pg_url, pg_props, \"rsbr.property\")\n",
    "    .select(\"property_id\", \"ListingID\", \"PublicRemarks\")\n",
    ")\n",
    "df1 = (\n",
    "    read_table(pg_url, pg_props, \"rsbr.embedding\")\n",
    "    .select(\"ListingID\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added = [row.ListingID for row in df1.collect()]\n",
    "df0 = df0.filter(~df0.ListingID.isin(added))\n",
    "to_embed = df0.select(\"ListingID\", \"PublicRemarks\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(added), len(to_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "cost_per_1k_tokens = 0.00013\n",
    "enc = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
    "tokens = [len(enc.encode(row[\"PublicRemarks\"])) for row in to_embed]\n",
    "costs = [cost_per_1k_tokens * (token_count / 1000) for token_count in tokens]\n",
    "print(f\"Total tokens: {sum(tokens)}\")\n",
    "print(f\"Total cost: ${sum(costs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def embed(row:Row) -> str:\n",
    "    client = OpenAI()\n",
    "    response = client.embeddings.create(input = row[\"PublicRemarks\"], model=\"text-embedding-3-small\")\n",
    "    return Row(ListingID=row[\"ListingID\"], PublicRemarks=row[\"PublicRemarks\"], Embedding=response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# Define a function to process a batch of embeddings\n",
    "def process_batch(batch):\n",
    "    with concurrent.futures.ThreadPoolExecutor(100) as executor:\n",
    "        futures = []\n",
    "        for data in batch:\n",
    "            futures.append(executor.submit(embed, data))\n",
    "\n",
    "        results = []\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            results.append(future.result())\n",
    "    return results\n",
    "\n",
    "# Split the 'to_embed' list into batches of 1000\n",
    "batch_size = 100\n",
    "batches = [to_embed[i:i+batch_size] for i in range(0, len(to_embed), batch_size)]\n",
    "\n",
    "schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"ListingID\", T.StringType(), False),\n",
    "        T.StructField(\"PublicRemarks\", T.StringType(), False),\n",
    "        T.StructField(\"Embedding\", T.StringType(), False)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Processing {len(to_embed)} records in {len(batches)} batches of {batch_size} records each\")\n",
    "total_processed = 0\n",
    "for i, batch in enumerate(batches):\n",
    "    if i +  1 > 275:\n",
    "        rows = process_batch(batch)\n",
    "        df = spark.createDataFrame(rows, schema)\n",
    "        df.write.csv(f\"{data_home}/embeddings/batch{str(i+1).zfill(6)}.csv\", mode=\"overwrite\", header=True)\n",
    "        total_processed += len(batch)\n",
    "        print(f\"Processed batch {i+1} of {len(batches)} for ({total_processed} of {len(to_embed)}) records\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
